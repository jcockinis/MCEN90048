{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from GeneralTools.auxiliary_functions import reformat_labels\n",
    "from GeneralTools.strings import FLAGS\n",
    "import time\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(train_images_raw, train_labels_raw), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "train_vis = train_images_raw\n",
    "labels_vis = train_labels_raw\n",
    "\n",
    "# flatten image data from num_samples x 28 x 28 to num_samples x 784\n",
    "train_images_raw = train_images_raw.reshape((train_images_raw.shape[0], 784))\n",
    "test_images = test_images.reshape((test_images.shape[0], 784))\n",
    "\n",
    "# reformat label data to num_samples x 10\n",
    "train_labels_raw = reformat_labels(train_labels_raw)\n",
    "test_labels = reformat_labels(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the dataset for batching\n",
    "features_placeholder = tf.placeholder(tf.float32, train_images_raw.shape)\n",
    "labels_placeholder = tf.placeholder(tf.int32, train_labels_raw.shape)\n",
    "dataset_tr = tf.data.Dataset.from_tensor_slices(\n",
    "    {\"features\": features_placeholder,\n",
    "    \"labels\": labels_placeholder})\n",
    "\n",
    "# scale the images\n",
    "dataset_tr = dataset_tr.map(lambda d: (d['features'] / 255.0, d['labels']))\n",
    "\n",
    "batch_size = 400\n",
    "shuffle = True\n",
    "buffer_size = 10000\n",
    "num_epoch = None # set this to None or -1 will repeat the dataset infinite times\n",
    "\n",
    "# shuffle\n",
    "if shuffle:\n",
    "    dataset_tr = dataset_tr.shuffle(buffer_size)\n",
    "        \n",
    "# make batch\n",
    "dataset_tr = dataset_tr.batch(batch_size)\n",
    "# repeat datasets for num_epoch\n",
    "dataset_tr = dataset_tr.repeat(num_epoch)\n",
    "\n",
    "# define an iterator that reads a batch each time\n",
    "iterator = dataset_tr.make_initializable_iterator()\n",
    "# read a batch\n",
    "train_images, train_labels = iterator.get_next()\n",
    "\n",
    "train_images = tf.cast(train_images, tf.float32)\n",
    "test_images = tf.cast(test_images, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer_nodes = 128\n",
    "output_layer_nodes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up NN (1 hidden layer, 1 output layer)\n",
    "with tf.variable_scope('LinearModel0', reuse=tf.AUTO_REUSE):\n",
    "    # now declare the weights connecting the input to the hidden layer of 10 nodes\n",
    "    w0 = tf.get_variable('weight0', shape=(train_images.shape[1], hidden_layer_nodes), dtype=tf.float32,\n",
    "                         initializer=tf.random_normal_initializer, trainable=True)\n",
    "    b0 = tf.get_variable('bias0', shape=[hidden_layer_nodes], dtype=tf.float32, initializer=tf.random_normal_initializer, trainable=True)\n",
    "    # and the weights connecting the hidden layer to the output layer\n",
    "    w1 = tf.get_variable('weight1', shape=(hidden_layer_nodes, output_layer_nodes), dtype=tf.float32,\n",
    "                         initializer=tf.random_normal_initializer, trainable=True)\n",
    "    b1 = tf.get_variable('bias1', shape=[output_layer_nodes], dtype=tf.float32, initializer=tf.random_normal_initializer, trainable=True)\n",
    "\n",
    "    # calculate the output of the hidden layer for training\n",
    "    train_hidden_out = tf.add(tf.matmul(train_images, w0), b0)\n",
    "    train_hidden_out = tf.nn.relu(train_hidden_out)\n",
    "\n",
    "    # now calculate NN output - in this case, use a softmax activated output layer for training\n",
    "    train_output_logits = tf.add(tf.matmul(train_hidden_out, w1), b1)\n",
    "    train_output = tf.nn.softmax(train_output_logits)\n",
    "\n",
    "    # calculate the output of the hidden layer for testing\n",
    "    test_hidden_out = tf.add(tf.matmul(test_images, w0), b0)\n",
    "    test_hidden_out = tf.nn.relu(test_hidden_out)\n",
    "\n",
    "    # now calculate NN output - in this case, use a softmax activated output layer for testing\n",
    "    test_output_logits = tf.add(tf.matmul(test_hidden_out, w1), b1)\n",
    "    test_output = tf.nn.softmax(test_output_logits)\n",
    "\n",
    "with tf.name_scope('LinearModel1'):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Jack\\Anaconda3\\envs\\MCEN90048\\lib\\site-packages\\tensorflow\\python\\ops\\losses\\losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "# define loss function\n",
    "train_loss = tf.losses.softmax_cross_entropy(train_labels, train_output_logits, reduction=tf.losses.Reduction.SUM_OVER_BATCH_SIZE, scope='train_loss')\n",
    "test_loss = tf.losses.softmax_cross_entropy(test_labels, test_output_logits, reduction=tf.losses.Reduction.SUM_OVER_BATCH_SIZE, scope='test_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine accuracy\n",
    "_,acc = tf.metrics.accuracy(test_output, test_labels)\n",
    "acc = 100*acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure the optimiser\n",
    "global_step = tf.get_variable(name='global_step', shape=[], dtype=tf.int32, initializer=tf.constant_initializer(0), trainable=False)\n",
    "init_learning_rate = 0.1\n",
    "opt = tf.train.GradientDescentOptimizer(learning_rate=init_learning_rate, name='GD')\n",
    "\n",
    "variable_list = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=None)\n",
    "images_list = opt.compute_gradients(train_loss, variable_list)\n",
    "opt_op = opt.apply_gradients(images_list, global_step=global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Tried to convert 'values' to a tensor and failed. Error: None values not supported.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\MCEN90048\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    510\u001b[0m                 \u001b[0mas_ref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_ref\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m                 preferred_dtype=default_dtype)\n\u001b[0m\u001b[0;32m    512\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\MCEN90048\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, ctx, accept_symbolic_tensors)\u001b[0m\n\u001b[0;32m   1174\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1175\u001b[1;33m       \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\MCEN90048\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[1;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[0;32m    303\u001b[0m   \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 304\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    305\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\MCEN90048\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name)\u001b[0m\n\u001b[0;32m    244\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[1;32m--> 245\u001b[1;33m                         allow_broadcast=True)\n\u001b[0m\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\MCEN90048\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    282\u001b[0m           \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverify_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 283\u001b[1;33m           allow_broadcast=allow_broadcast))\n\u001b[0m\u001b[0;32m    284\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\MCEN90048\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[1;34m(values, dtype, shape, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    453\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mvalues\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 454\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"None values not supported.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    455\u001b[0m     \u001b[1;31m# if dtype is provided, forces numpy array to be the type\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: None values not supported.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\MCEN90048\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    524\u001b[0m               observed = ops.internal_convert_to_tensor(\n\u001b[1;32m--> 525\u001b[1;33m                   values, as_ref=input_arg.is_ref).dtype.name\n\u001b[0m\u001b[0;32m    526\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\MCEN90048\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, ctx, accept_symbolic_tensors)\u001b[0m\n\u001b[0;32m   1174\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1175\u001b[1;33m       \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\MCEN90048\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[1;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[0;32m    303\u001b[0m   \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 304\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    305\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\MCEN90048\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name)\u001b[0m\n\u001b[0;32m    244\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[1;32m--> 245\u001b[1;33m                         allow_broadcast=True)\n\u001b[0m\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\MCEN90048\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    282\u001b[0m           \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverify_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 283\u001b[1;33m           allow_broadcast=allow_broadcast))\n\u001b[0m\u001b[0;32m    284\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\MCEN90048\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[1;34m(values, dtype, shape, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    453\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mvalues\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 454\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"None values not supported.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    455\u001b[0m     \u001b[1;31m# if dtype is provided, forces numpy array to be the type\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: None values not supported.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-b5b19b9e3912>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mvar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mvar_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m':'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistogram\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'image_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mvar_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistogram\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvar_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0msummary_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\MCEN90048\\lib\\site-packages\\tensorflow\\python\\summary\\summary.py\u001b[0m in \u001b[0;36mhistogram\u001b[1;34m(name, values, collections, family)\u001b[0m\n\u001b[0;32m    175\u001b[0m       default_name='HistogramSummary') as (tag, scope):\n\u001b[0;32m    176\u001b[0m     val = _gen_logging_ops.histogram_summary(\n\u001b[1;32m--> 177\u001b[1;33m         tag=tag, values=values, name=scope)\n\u001b[0m\u001b[0;32m    178\u001b[0m     \u001b[0m_summary_op_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSUMMARIES\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\MCEN90048\\lib\\site-packages\\tensorflow\\python\\ops\\gen_logging_ops.py\u001b[0m in \u001b[0;36mhistogram_summary\u001b[1;34m(tag, values, name)\u001b[0m\n\u001b[0;32m    309\u001b[0m   \u001b[1;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m   _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m--> 311\u001b[1;33m         \"HistogramSummary\", tag=tag, values=values, name=name)\n\u001b[0m\u001b[0;32m    312\u001b[0m   \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\MCEN90048\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    527\u001b[0m               raise ValueError(\n\u001b[0;32m    528\u001b[0m                   \u001b[1;34m\"Tried to convert '%s' to a tensor and failed. Error: %s\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 529\u001b[1;33m                   (input_name, err))\n\u001b[0m\u001b[0;32m    530\u001b[0m             prefix = (\"Input '%s' of '%s' Op has type %s that does not match\" %\n\u001b[0;32m    531\u001b[0m                       (input_name, op_type_name, observed))\n",
      "\u001b[1;31mValueError\u001b[0m: Tried to convert 'values' to a tensor and failed. Error: None values not supported."
     ]
    }
   ],
   "source": [
    "# configure the summary\n",
    "# summary op is always pinned to CPU\n",
    "tf.summary.histogram('Input_Weights', w0)\n",
    "tf.summary.histogram('Input_Bias', b0)\n",
    "tf.summary.histogram('Hidden_Weights', w1)\n",
    "tf.summary.histogram('Hidden_Bias', b1)\n",
    "tf.summary.scalar('Training_Loss', train_loss)\n",
    "tf.summary.scalar('Testing_Loss', test_loss)\n",
    "for image in images_list:\n",
    "    var_image = image[0]\n",
    "    var = image[1]\n",
    "    var_name = var.name.replace(':', '_')\n",
    "    tf.summary.histogram('image_' + var_name, var_image)\n",
    "    tf.summary.histogram(var_name, var)\n",
    "summary_op = tf.summary.merge_all()\n",
    "summary_folder = os.path.join(FLAGS.DEFAULT_OUT, 'MLPBaseline' + '_log', 'SGD_event')\n",
    "if not os.path.exists(summary_folder):\n",
    "    os.makedirs(summary_folder)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: training loss is 169.9483; test loss is 43051.8672; accuracy is 83.2440%\n",
      "Step 21: training loss is 7.8894; test loss is 2015.1200; accuracy is 87.4390%\n",
      "Step 41: training loss is 6.9965; test loss is 1433.8942; accuracy is 89.0020%\n",
      "Step 61: training loss is 4.7446; test loss is 1132.1034; accuracy is 89.8942%\n",
      "Step 81: training loss is 4.2114; test loss is 922.9583; accuracy is 90.4410%\n",
      "Step 101: training loss is 2.8853; test loss is 785.5249; accuracy is 90.7920%\n",
      "Step 121: training loss is 2.5037; test loss is 689.2629; accuracy is 91.0341%\n",
      "Step 141: training loss is 3.2007; test loss is 602.6517; accuracy is 91.2094%\n",
      "Step 161: training loss is 2.2539; test loss is 559.1585; accuracy is 91.3309%\n",
      "Step 181: training loss is 1.8680; test loss is 496.3517; accuracy is 91.4175%\n",
      "Step 201: training loss is 1.7224; test loss is 466.9388; accuracy is 91.4848%\n",
      "Step 221: training loss is 1.4040; test loss is 436.5746; accuracy is 91.5285%\n",
      "Step 241: training loss is 1.4024; test loss is 410.4310; accuracy is 91.5744%\n",
      "Step 261: training loss is 1.8424; test loss is 395.4897; accuracy is 91.6016%\n",
      "Step 281: training loss is 1.7064; test loss is 366.4135; accuracy is 91.6244%\n",
      "Step 301: training loss is 1.5556; test loss is 350.3063; accuracy is 91.6487%\n",
      "Step 321: training loss is 1.4558; test loss is 331.8456; accuracy is 91.6831%\n",
      "Step 341: training loss is 1.3541; test loss is 319.7632; accuracy is 91.7084%\n",
      "Step 361: training loss is 1.2160; test loss is 308.9803; accuracy is 91.7330%\n",
      "Step 381: training loss is 1.1898; test loss is 304.6357; accuracy is 91.7480%\n",
      "Step 400: training loss is 1.5271; test loss is 295.8155; accuracy is 91.7650%\n",
      "Training for 400 steps complete in 50.49 seconds with a final accuracy of 91.77% \n"
     ]
    }
   ],
   "source": [
    "# Call a session\n",
    "sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=False))\n",
    "# initialise the graph\n",
    "init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "sess.run(init_op)\n",
    "\n",
    "# configure where to write the summary file\n",
    "summary_writer = tf.summary.FileWriter(summary_folder, sess.graph)\n",
    "# reset the graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# must run initializer for iterator first that feeds in dataset\n",
    "sess.run(iterator.initializer, feed_dict={features_placeholder: train_images_raw, labels_placeholder: train_labels_raw})\n",
    "\n",
    "# run the session\n",
    "start_time = time.time()\n",
    "max_iter = 400\n",
    "for step in range(max_iter):\n",
    "    loss_value, _, global_step_value = sess.run([train_loss, opt_op, global_step])\n",
    "    \n",
    "    # check for NAN outcome\n",
    "    assert not np.isnan(loss_value),\\\n",
    "        'Model diverged with loss = {} at step {}'.format(loss_value, global_step_value)\n",
    "    \n",
    "    # add summary and print loss every query step\n",
    "    if global_step_value % 20 == 1 or global_step_value == max_iter:\n",
    "        test_loss_value, accuracy = sess.run([test_loss, acc])\n",
    "        if summary_op is not None:\n",
    "                summary_str = sess.run(summary_op)\n",
    "                summary_writer.add_summary(summary_str, global_step=global_step_value)\n",
    "        print('Step {}: training loss is {:.4f}; test loss is {:.4f}; accuracy is {:.4f}%'.format(global_step_value, loss_value, test_loss_value, accuracy))\n",
    "\n",
    "duration = time.time() - start_time        \n",
    "print('Training for {} steps complete in {:.2f} seconds with a final accuracy of {:.2f}% '.format(max_iter, duration, accuracy))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of images has been changed to (400, 28, 28, 3)\n",
      "Shape of images has been changed to (20, 28, 20, 28, 3)\n",
      "Shape of images has been changed to (560, 560, 3)\n"
     ]
    }
   ],
   "source": [
    "# Data Visualisation\n",
    "\n",
    "from tensorflow.contrib.tensorboard.plugins import projector\n",
    "import os.path, os, warnings, imageio\n",
    "\n",
    "# prepare folder\n",
    "folder  = 'DataVisual'\n",
    "filename = 'mnist'\n",
    "\n",
    "summary_folder = os.path.join(FLAGS.DEFAULT_OUT, folder)\n",
    "\n",
    "if not os.path.exists(summary_folder):\n",
    "    os.makedirs(summary_folder)\n",
    "\n",
    "embedding_path = os.path.join(summary_folder, filename + '_embedding.ckpt')\n",
    "sprite_path = os.path.join(summary_folder, filename + '.png')\n",
    "label_path = os.path.join(summary_folder, filename + '_label.tsv')    \n",
    "\n",
    "# prepare data, sprite images and files\n",
    "embedding_data = train_vis[0:400]   #np.reshape(train_vis, (batch_size, -1))\n",
    "images = train_vis[0:400]  # shape [400, 28, 28]\n",
    "image_size = train_vis.shape[1:]  # [28, 28]\n",
    "labels = labels_vis[0:400]\n",
    "\n",
    "# write label to file\n",
    "if os.path.isfile(label_path):\n",
    "    warnings.warn(\n",
    "        'Label file {} already exists, thus this step is ignored.'.format(label_path))\n",
    "else:\n",
    "    metadata_file = open(label_path, 'w')\n",
    "    metadata_file.write('Name\\tClass\\n')\n",
    "    for index, label in enumerate(labels):\n",
    "            metadata_file.write('%06d\\t%s\\n' % (index, str(label)))\n",
    "    metadata_file.close()\n",
    "\n",
    "# write images to sprite\n",
    "if os.path.isfile(sprite_path):\n",
    "    warnings.warn(\n",
    "        'Sprite file {} already exists, thus this step is ignored.'.format(sprite_path))\n",
    "else:\n",
    "    # extend image shapes to [batch size, height, width, 3]\n",
    "    if len(images.shape) == 3:  # if dimension of image is 3, extend it to 4\n",
    "        images = np.tile(images[..., np.newaxis], (1, 1, 1, 3))\n",
    "        print('Shape of images has been changed to {}'.format(images.shape))\n",
    "    if images.shape[3] == 1:  # if last dimension is 1, extend it to 3\n",
    "        images = np.tile(images, (1, 1, 1, 3))\n",
    "        print('Shape of images has been changed to {}'.format(images.shape))\n",
    "        \n",
    "# invert images for mnist\n",
    "images = 1 - images\n",
    "    \n",
    "# Tile the individual thumbnails into an image\n",
    "mesh_num = (20, 20)\n",
    "new_shape = mesh_num + images.shape[1:]  # (20, 20, 28, 28, 3)\n",
    "images = images.reshape(new_shape).transpose((0, 2, 1, 3, 4))\n",
    "print('Shape of images has been changed to {}'.format(images.shape))\n",
    "images = images.reshape((mesh_num[0] * images.shape[1], mesh_num[1] * images.shape[3]) + images.shape[4:])\n",
    "print('Shape of images has been changed to {}'.format(images.shape))\n",
    "images = (images * 255).astype(np.uint8)\n",
    "# save images to file\n",
    "imageio.imwrite(sprite_path, images)\n",
    "\n",
    "# write data to ckpt\n",
    "if os.path.isfile(embedding_path):\n",
    "    warnings.warn(\n",
    "        'Embedding file {} already exists, thus this step is ignored.'.format(embedding_path))\n",
    "else:\n",
    "    # register a session\n",
    "    sess = tf.Session()\n",
    "    # prepare a embedding variable\n",
    "    # note this must be a variable, not a tensor/constant\n",
    "    embedding_var = tf.Variable(embedding_data, name='em_data')\n",
    "    sess.run(embedding_var.initializer)\n",
    "    # configure the embedding projector\n",
    "    config = projector.ProjectorConfig()\n",
    "    embedding = config.embeddings.add()\n",
    "    embedding.tensor_name = embedding_var.name\n",
    "    # add metadata (label) to embedding\n",
    "    if label_path is not None:\n",
    "        embedding.metadata_path = label_path\n",
    "    # add sprite image to embedding\n",
    "    if sprite_path is not None:\n",
    "        embedding.sprite.image_path = sprite_path\n",
    "        embedding.sprite.single_image_dim.extend(image_size)\n",
    "    # finalize embedding setting\n",
    "    embedding_writer = tf.summary.FileWriter(summary_folder)\n",
    "    projector.visualize_embeddings(embedding_writer, config)\n",
    "    embedding_saver = tf.train.Saver([embedding_var], max_to_keep=1)\n",
    "    embedding_saver.save(sess, embedding_path)\n",
    "    # close all\n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
